"""
í†µí•© ìˆ˜ì˜ í¬ë¡¤ë§ ì„œë¹„ìŠ¤
1. ê¸°ë³¸ ìŠ¤ì¼€ì¤„ (ì´ìš©ì•ˆë‚´ í˜ì´ì§€) í¬ë¡¤ë§
2. ì›”ë³„ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§
3. ë°ì´í„° ë³‘í•© ë° ì €ì¥

ì§€ì› ê¸°ê´€:
- ì„±ë‚¨ì‹œì²­ì†Œë…„ì²­ë…„ì¬ë‹¨ (snyouth): 3ê°œ ìœ ìŠ¤ì„¼í„°
- ì„±ë‚¨ë„ì‹œê°œë°œê³µì‚¬ (snhdc): 5ê°œ ì²´ìœ¡ì„¼í„°

ë¦¬íŒ©í† ë§: ê° ì±…ì„ë³„ ì„œë¹„ìŠ¤ë¡œ ë¶„ë¦¬
- CrawlingService: í¬ë¡¤ë§ ì‹¤í–‰
- ParsingService: íŒŒì‹± ì‹¤í–‰
- StorageService: ë°ì´í„° ì €ì¥
"""
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

from .crawling_service import CrawlingService
from .parsing_service import ParsingService
from .storage_service import StorageService
from dto.crawler_dto import PostDetail

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

STORAGE_DIR = Path(__file__).parent.parent / "storage"
DOWNLOAD_DIR = Path(__file__).parent.parent / "downloads"


class SwimCrawlerService:
    """í†µí•© ìˆ˜ì˜ í¬ë¡¤ë§ ì„œë¹„ìŠ¤ (snyouth + snhdc)"""

    def __init__(self):
        self.storage = StorageService(storage_dir=STORAGE_DIR)

    def crawl_base_schedules(self, save: bool = True) -> Dict[str, List[Dict]]:
        """
        ê¸°ë³¸ ìŠ¤ì¼€ì¤„ í¬ë¡¤ë§ (ì´ìš©ì•ˆë‚´ í˜ì´ì§€)
        ì–‘ìª½ ê¸°ê´€ ëª¨ë‘ í¬ë¡¤ë§

        Args:
            save: JSON íŒŒì¼ë¡œ ì €ì¥ ì—¬ë¶€

        Returns:
            {"snyouth": [...], "snhdc": [...]} í˜•íƒœì˜ ì‹œì„¤ ê¸°ë³¸ ì •ë³´
        """
        logger.info("=== ê¸°ë³¸ ìŠ¤ì¼€ì¤„ í¬ë¡¤ë§ ì‹œì‘ ===")

        all_facilities = {}

        # ê° ê¸°ê´€ë³„ í¬ë¡¤ë§
        for org_key in ["snyouth", "snhdc"]:
            crawling_service = CrawlingService(org_key)
            facilities = crawling_service.crawl_base_schedules()
            all_facilities[org_key] = facilities

            if save:
                self.storage.save_base_schedules(org_key, facilities)

        total = len(all_facilities["snyouth"]) + len(all_facilities["snhdc"])
        logger.info(f"ê¸°ë³¸ ìŠ¤ì¼€ì¤„ í¬ë¡¤ë§ ì™„ë£Œ: ì´ {total}ê°œ ì‹œì„¤")
        return all_facilities

    def crawl_monthly_notices(self, keyword: str = "ìˆ˜ì˜", max_pages: int = 5, save: bool = True) -> Dict[str, List[Dict]]:
        """
        ì›”ë³„ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§
        ì–‘ìª½ ê¸°ê´€ ëª¨ë‘ í¬ë¡¤ë§

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜
            save: JSON íŒŒì¼ë¡œ ì €ì¥ ì—¬ë¶€

        Returns:
            {"snyouth": [...], "snhdc": [...]} í˜•íƒœì˜ ê²Œì‹œê¸€ ìƒì„¸ ì •ë³´
        """
        logger.info("=== ì›”ë³„ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ì‹œì‘ ===")

        all_notices = {}

        # ê° ê¸°ê´€ë³„ í¬ë¡¤ë§
        for org_key in ["snyouth", "snhdc"]:
            crawling_service = CrawlingService(org_key)
            details: List[PostDetail] = crawling_service.crawl_monthly_notices(keyword, max_pages)

            # PostDetailì„ dictë¡œ ë³€í™˜
            all_notices[org_key] = [self._post_detail_to_dict(d) for d in details]

            if save:
                self.storage.save_monthly_notices(org_key, all_notices[org_key])

        total = len(all_notices["snyouth"]) + len(all_notices["snhdc"])
        logger.info(f"ì›”ë³„ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ì™„ë£Œ: ì´ {total}ê°œ")
        return all_notices

    @staticmethod
    def _post_detail_to_dict(detail: PostDetail) -> Dict:
        """PostDetailì„ dictë¡œ ë³€í™˜"""
        return {
            "post_id": detail.post_id,
            "title": detail.title,
            "facility_name": detail.facility_name,
            "date": detail.date,
            "content_html": detail.content_html,
            "content_text": detail.content_text,
            "source_url": detail.source_url,
            "attachments": [
                {
                    "filename": att.filename,
                    "size": att.file_size,
                    "ext": att.file_ext,
                    "url": att.download_url
                }
                for att in detail.attachments
            ],
            "has_attachment": len(detail.attachments) > 0,
            "file_hwp": next((att.filename for att in detail.attachments if att.file_ext == "hwp"), None),
            "file_pdf": next((att.filename for att in detail.attachments if att.file_ext == "pdf"), None)
        }

    def parse_snhdc_attachments(self, monthly_notices: Optional[Dict[str, List[Dict]]] = None,
                                 save: bool = True, max_files: int = 10) -> List[Dict]:
        """
        SNHDC ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±

        Args:
            monthly_notices: ì›”ë³„ ê³µì§€ì‚¬í•­ (ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ)
            save: íŒŒì‹± ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            max_files: ìµœëŒ€ ì²˜ë¦¬ íŒŒì¼ ìˆ˜

        Returns:
            íŒŒì‹±ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("=== SNHDC ì²¨ë¶€íŒŒì¼ íŒŒì‹± ì‹œì‘ ===")

        # ë°ì´í„° ë¡œë“œ
        if monthly_notices is None:
            snhdc_notices = self.storage.load_monthly_notices("snhdc")
        else:
            snhdc_notices = monthly_notices.get("snhdc", [])

        # ì²¨ë¶€íŒŒì¼ì´ ìˆëŠ” ê³µì§€ë§Œ í•„í„°ë§
        notices_with_files = [n for n in snhdc_notices if n.get("has_attachment")]
        logger.info(f"ì²¨ë¶€íŒŒì¼ì´ ìˆëŠ” ê³µì§€: {len(notices_with_files)}ê°œ")

        if not notices_with_files:
            logger.warning("ì²¨ë¶€íŒŒì¼ì´ ìˆëŠ” ê³µì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        notices_to_process = notices_with_files[:max_files]
        logger.info(f"ì²˜ë¦¬í•  ê³µì§€: {len(notices_to_process)}ê°œ")

        # ParsingService ì‚¬ìš©
        parsing_service = ParsingService(download_dir=DOWNLOAD_DIR / "snhdc")

        # Dictë¥¼ PostDetailë¡œ ë³€í™˜ í›„ íŒŒì‹±
        parsed_results = []
        for notice_dict in notices_to_process:
            # Dictë¥¼ PostDetailë¡œ ë³€í™˜
            post_detail = self._dict_to_post_detail(notice_dict)

            # íŒŒì‹± ì‹¤í–‰
            result = parsing_service.parse_from_notice(post_detail)
            if result:
                parsed_results.append(result)

        logger.info(f"íŒŒì‹± ì™„ë£Œ: {len(parsed_results)}/{len(notices_to_process)}ê°œ ì„±ê³µ")

        # ê²°ê³¼ ì €ì¥
        if save and parsed_results:
            self.storage.save_parsed_schedules("snhdc", parsed_results)

        return parsed_results

    @staticmethod
    def _dict_to_post_detail(notice_dict: Dict) -> PostDetail:
        """Dictë¥¼ PostDetailë¡œ ë³€í™˜"""
        from dto.crawler_dto import Attachment

        attachments = [
            Attachment(
                filename=att["filename"],
                file_size=att["size"],
                file_ext=att["ext"],
                download_url=att["url"]
            )
            for att in notice_dict.get("attachments", [])
        ]

        return PostDetail(
            post_id=notice_dict.get("post_id", ""),
            title=notice_dict.get("title", ""),
            facility_name=notice_dict.get("facility_name", ""),
            date=notice_dict.get("date", ""),
            content_html=notice_dict.get("content_html", ""),
            content_text=notice_dict.get("content_text", ""),
            attachments=attachments,
            source_url=notice_dict.get("source_url", "")
        )


    def merge_schedules(self, base_schedules: Optional[Dict[str, List[Dict]]] = None,
                       monthly_notices: Optional[Dict[str, List[Dict]]] = None) -> Dict:
        """
        ê¸°ë³¸ ìŠ¤ì¼€ì¤„ê³¼ ì›”ë³„ ê³µì§€ì‚¬í•­ ë³‘í•©

        ì „ëµ:
        1. ê¸°ë³¸ ìŠ¤ì¼€ì¤„ì„ baselineìœ¼ë¡œ ì‚¬ìš©
        2. ì›”ë³„ ê³µì§€ì‚¬í•­ì—ì„œ ì„ì‹œ ë³€ê²½ì‚¬í•­ ì¶”ì¶œ
        3. íŠ¹ì • ë‚ ì§œ/ê¸°ê°„ì— ëŒ€í•œ override ì •ë³´ ì œê³µ

        Args:
            base_schedules: {"snyouth": [...], "snhdc": [...]} í˜•íƒœ (ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ)
            monthly_notices: {"snyouth": [...], "snhdc": [...]} í˜•íƒœ (ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë¡œë“œ)

        Returns:
            ë³‘í•©ëœ ìŠ¤ì¼€ì¤„ ì •ë³´
        """
        logger.info("=== ìŠ¤ì¼€ì¤„ ë³‘í•© ì‹œì‘ ===")

        # ë°ì´í„° ë¡œë“œ
        if base_schedules is None:
            base_schedules = {}
            for org_key in ["snyouth", "snhdc"]:
                facilities = self.storage.load_base_schedules(org_key)
                base_schedules[org_key] = facilities

        if monthly_notices is None:
            monthly_notices = {}
            for org_key in ["snyouth", "snhdc"]:
                notices = self.storage.load_monthly_notices(org_key)
                monthly_notices[org_key] = notices

        # í†µê³„
        snyouth_base_count = len(base_schedules.get("snyouth", []))
        snhdc_base_count = len(base_schedules.get("snhdc", []))
        snyouth_notice_count = len(monthly_notices.get("snyouth", []))
        snhdc_notice_count = len(monthly_notices.get("snhdc", []))

        # ì‹œì„¤ë³„ë¡œ ê·¸ë£¹í™”
        merged = {
            "meta": {
                "merged_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "organizations": {
                    "snyouth": {
                        "name": "ì„±ë‚¨ì‹œì²­ì†Œë…„ì²­ë…„ì¬ë‹¨",
                        "base_schedule_count": snyouth_base_count,
                        "monthly_notice_count": snyouth_notice_count
                    },
                    "snhdc": {
                        "name": "ì„±ë‚¨ë„ì‹œê°œë°œê³µì‚¬",
                        "base_schedule_count": snhdc_base_count,
                        "monthly_notice_count": snhdc_notice_count
                    }
                }
            },
            "facilities": {}
        }

        # 1. ê¸°ë³¸ ìŠ¤ì¼€ì¤„ì„ baselineìœ¼ë¡œ ì„¤ì • (ì–‘ìª½ ê¸°ê´€ ëª¨ë‘)
        for org_key in ["snyouth", "snhdc"]:
            org_name = merged["meta"]["organizations"][org_key]["name"]
            for facility in base_schedules.get(org_key, []):
                facility_name = facility.get("facility_name")
                merged["facilities"][facility_name] = {
                    "organization": org_name,
                    "org_key": org_key,
                    "base_schedule": facility,
                    "monthly_updates": [],
                    "current_schedule": facility.copy()  # í˜„ì¬ ì ìš©ì¤‘ì¸ ìŠ¤ì¼€ì¤„
                }

        # 2. ì›”ë³„ ê³µì§€ì‚¬í•­ ì¶”ê°€ (ì–‘ìª½ ê¸°ê´€ ëª¨ë‘)
        for org_key in ["snyouth", "snhdc"]:
            for notice in monthly_notices.get(org_key, []):
                # ì‹œì„¤ëª… ì¶”ì¶œ (ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì›)
                facility_name = (
                    notice.get("facility_name") or
                    notice.get("pool_name") or
                    ""
                )

                # ì‹œì„¤ëª… ë§¤ì¹­ (ìœ ì—°í•œ ë§¤ì¹­)
                matched_facility = self._match_facility_name(facility_name, merged["facilities"].keys())

                if matched_facility:
                    merged["facilities"][matched_facility]["monthly_updates"].append({
                        "title": notice.get("title", ""),
                        "valid_month": notice.get("valid_month", ""),
                        "date": notice.get("date", ""),
                        "source_url": notice.get("source_url", ""),
                        "content_text_preview": notice.get("content_text", "")[:200] + "..." if notice.get("content_text") else "",
                        "has_attachment": notice.get("has_attachment", False),
                        "file_hwp": notice.get("file_hwp"),
                        "file_pdf": notice.get("file_pdf")
                    })

        logger.info("ìŠ¤ì¼€ì¤„ ë³‘í•© ì™„ë£Œ")
        return merged

    def _match_facility_name(self, name: str, candidates: List[str]) -> Optional[str]:
        """ì‹œì„¤ëª… ë§¤ì¹­ (ìœ ì—°í•œ ë§¤ì¹­)"""
        from models.enum.facility import Facility

        # ì •í™•íˆ ì¼ì¹˜
        if name in candidates:
            return name

        # ë¶€ë¶„ ì¼ì¹˜
        for candidate in candidates:
            if name in candidate or candidate in name:
                return candidate

        # ë³„ì¹­ ë§¤ì¹­ (Facility Enum ì‚¬ìš©)
        for facility_enum in Facility:
            facility_info = facility_enum.value
            for alias in facility_info.aliases:
                if alias in name and facility_info.name in candidates:
                    return facility_info.name

        return None


# í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    service = SwimCrawlerService()

    # 1. ê¸°ë³¸ ìŠ¤ì¼€ì¤„ í¬ë¡¤ë§
    print("\n" + "="*60)
    print("1. ê¸°ë³¸ ìŠ¤ì¼€ì¤„ í¬ë¡¤ë§ (snyouth + snhdc)")
    print("="*60)
    base_schedules = service.crawl_base_schedules(save=True)
    snyouth_count = len(base_schedules.get("snyouth", []))
    snhdc_count = len(base_schedules.get("snhdc", []))
    print(f"  ì„±ë‚¨ì‹œì²­ì†Œë…„ì²­ë…„ì¬ë‹¨: {snyouth_count}ê°œ")
    print(f"  ì„±ë‚¨ë„ì‹œê°œë°œê³µì‚¬: {snhdc_count}ê°œ")
    print(f"  ì´ {snyouth_count + snhdc_count}ê°œ ì‹œì„¤")

    # 2. ì›”ë³„ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§
    print("\n" + "="*60)
    print("2. ì›”ë³„ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ (snyouth + snhdc)")
    print("="*60)
    monthly_notices = service.crawl_monthly_notices(keyword="ìˆ˜ì˜", max_pages=2, save=True)
    snyouth_notice_count = len(monthly_notices.get("snyouth", []))
    snhdc_notice_count = len(monthly_notices.get("snhdc", []))
    print(f"  ì„±ë‚¨ì‹œì²­ì†Œë…„ì²­ë…„ì¬ë‹¨: {snyouth_notice_count}ê°œ")
    print(f"  ì„±ë‚¨ë„ì‹œê°œë°œê³µì‚¬: {snhdc_notice_count}ê°œ")
    print(f"  ì´ {snyouth_notice_count + snhdc_notice_count}ê°œ ê³µì§€")

    # 3. SNHDC ì²¨ë¶€íŒŒì¼ íŒŒì‹±
    print("\n" + "="*60)
    print("3. SNHDC ì²¨ë¶€íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±")
    print("="*60)
    parsed_attachments = service.parse_snhdc_attachments(monthly_notices, save=True, max_files=5)
    print(f"  íŒŒì‹± ì™„ë£Œ: {len(parsed_attachments)}ê°œ")
    for result in parsed_attachments[:3]:  # ì²˜ìŒ 3ê°œë§Œ
        print(f"    - [{result['facility_name']}] {result.get('valid_month', 'N/A')}")
        print(f"      íŒŒì¼: {result['source_file']}")
        print(f"      ìŠ¤ì¼€ì¤„: {len(result.get('schedules', []))}ê°œ")

    # 4. ë°ì´í„° ë³‘í•©
    print("\n" + "="*60)
    print("4. ìŠ¤ì¼€ì¤„ ë³‘í•©")
    print("="*60)
    merged = service.merge_schedules(base_schedules, monthly_notices)
    print(f"ë³‘í•© ì™„ë£Œ: {len(merged['facilities'])}ê°œ ì‹œì„¤")

    # ë³‘í•© ê²°ê³¼ ì¶œë ¥ (ì¡°ì§ë³„ë¡œ)
    for org_key in ["snyouth", "snhdc"]:
        org_facilities = {
            name: data for name, data in merged["facilities"].items()
            if data.get("org_key") == org_key
        }

        if org_facilities:
            org_name = merged["meta"]["organizations"][org_key]["name"]
            print(f"\n{'='*60}")
            print(f"{org_name} ({len(org_facilities)}ê°œ ì‹œì„¤)")
            print(f"{'='*60}")

            for facility_name, facility_data in list(org_facilities.items())[:3]:  # ì²˜ìŒ 3ê°œë§Œ
                print(f"\n  [{facility_name}]")
                weekday_schedule = facility_data['base_schedule'].get('weekday_schedule', [])
                print(f"    í‰ì¼ ìŠ¤ì¼€ì¤„: {len(weekday_schedule)}ê°œ")
                print(f"    ì›”ë³„ ì—…ë°ì´íŠ¸: {len(facility_data['monthly_updates'])}ê°œ")

                if facility_data['monthly_updates']:
                    print("    ìµœê·¼ ê³µì§€:")
                    for update in facility_data['monthly_updates'][:2]:  # ì²˜ìŒ 2ê°œë§Œ
                        title = update.get('title', '')
                        date = update.get('date', '')
                        has_file = update.get('has_attachment', False)
                        file_marker = " [ğŸ“]" if has_file else ""
                        print(f"      - [{date}] {title}{file_marker}")

    # ë³‘í•© ê²°ê³¼ ì €ì¥
    service.storage.save_merged_schedules(merged)
    print(f"\n{'='*60}")
    print(f"ë³‘í•© ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    print(f"{'='*60}")
